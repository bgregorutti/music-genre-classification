{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extractoring and preprocessing data\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Keras\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulateSequence(n):\n",
    "    dictionary = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "    length = [500] #np.random.randint(50, 100, n)\n",
    "    encoder = LabelEncoder().fit(dictionary)\n",
    "    n_vocab = len(dictionary)\n",
    "    \n",
    "    if n == 1:\n",
    "        seq_str = np.random.choice(dictionary, length[0])\n",
    "        sequences = encoder.transform(seq_str)\n",
    "    \n",
    "    else:\n",
    "        sequences = []\n",
    "        for i in range(n):\n",
    "            seq_str = np.random.choice(dictionary, length[i])\n",
    "            seq_int = encoder.transform(seq_str)\n",
    "            sequences.append(seq_int)\n",
    "    \n",
    "    return sequences, n_vocab, encoder\n",
    "\n",
    "def processSequence(notes, n_vocab):\n",
    "    \n",
    "    sequence_length = 100\n",
    "    \n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    n_inputs = len(notes)-sequence_length\n",
    "    \n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(n_inputs):\n",
    "        network_input.append(notes[i:i+sequence_length])\n",
    "        network_output.append(notes[i+sequence_length])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    # Categorize the targets\n",
    "    network_output = to_categorical(network_output)\n",
    "\n",
    "    return network_input, network_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 100, 1), (400, 7), (100, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes, n_vocab, encoder = simulateSequence(1)\n",
    "X, y = processSequence(notes, n_vocab)\n",
    "\n",
    "_, input_shape_1, input_shape_2 = X.shape\n",
    "input_shape = (input_shape_1, input_shape_2)\n",
    "X.shape, y.shape, input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=input_shape, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_vocab, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "400/400 [==============================] - 36s 90ms/step - loss: 3.0038 - acc: 0.1550\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - 25s 61ms/step - loss: 2.1630 - acc: 0.1400\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - 25s 63ms/step - loss: 2.1495 - acc: 0.1450\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - 25s 61ms/step - loss: 2.1593 - acc: 0.1375\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 2.1413 - acc: 0.1500\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - 24s 61ms/step - loss: 2.0740 - acc: 0.1600\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 2.0854 - acc: 0.1625\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - 28s 70ms/step - loss: 2.0881 - acc: 0.1650\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - 26s 64ms/step - loss: 2.0770 - acc: 0.1275\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - 25s 63ms/step - loss: 2.5249 - acc: 0.1400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff9f0b4c198>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=10)\n",
    "#model.fit(X_train, y_train, batch_size=128, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(pd.Series(model.evaluate(X_test, y_test, batch_size=128), index=model.metrics_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "musicGenerator = Sequential()\n",
    "musicGenerator.add(LSTM(256, input_shape=input_shape, return_sequences=True))\n",
    "musicGenerator.add(Dropout(0.3))\n",
    "musicGenerator.add(LSTM(512, return_sequences=True))\n",
    "musicGenerator.add(Dropout(0.3))\n",
    "musicGenerator.add(LSTM(256))\n",
    "musicGenerator.add(Dense(256))\n",
    "musicGenerator.add(Dropout(0.3))\n",
    "musicGenerator.add(Dense(n_vocab, activation='softmax'))\n",
    "\n",
    "musicGenerator.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# Load the weights to each node\n",
    "musicGenerator.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = np.random.randint(0, len(X)-1)\n",
    "\n",
    "# Fix an initial note\n",
    "pattern = X[start]\n",
    "\n",
    "prediction_output = []\n",
    "\n",
    "# generate notes\n",
    "for _ in range(10):\n",
    "\n",
    "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    #prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "    # Predicted class    \n",
    "    prediction = np.argmax(musicGenerator.predict(prediction_input, verbose=0))\n",
    "    print(prediction)\n",
    "    \n",
    "    # Predicted note\n",
    "    result = encoder.inverse_transform([prediction])\n",
    "    prediction_output.append(result[0])\n",
    "\n",
    "    # Update the pattern\n",
    "    pattern = np.append(pattern, prediction / n_vocab)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'B')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = X[0]\n",
    "prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "#prediction_input = prediction_input / float(n_vocab)    \n",
    "prediction = np.argmax(musicGenerator.predict(prediction_input, verbose=0))\n",
    "prediction, encoder.inverse_transform([prediction])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
